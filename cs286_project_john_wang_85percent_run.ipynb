{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install karateclub"
      ],
      "metadata": {
        "id": "bbGhUJ0yZbEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d2bc9e-4c8d-4dd3-da7a-d5bfd0d3b32b"
      },
      "id": "bbGhUJ0yZbEJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: karateclub in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: networkx<2.7 in /usr/local/lib/python3.10/dist-packages (from karateclub) (2.6.3)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from karateclub) (4.3.1)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from karateclub) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.2.2)\n",
            "Requirement already satisfied: pygsp in /usr/local/lib/python3.10/dist-packages (from karateclub) (0.5.1)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from karateclub) (4.65.0)\n",
            "Requirement already satisfied: numpy<1.23.0 in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.22.4)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from karateclub) (0.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.10.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.10/dist-packages (from karateclub) (0.16)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.16.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->karateclub) (6.3.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->karateclub) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->karateclub) (2.8.2)\n",
            "Requirement already satisfied: Levenshtein==0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->karateclub) (0.21.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.0->python-Levenshtein->karateclub) (3.0.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->karateclub) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->karateclub) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f187eb45",
      "metadata": {
        "id": "f187eb45"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "#https://stackoverflow.com/questions/38015181/accuracy-score-valueerror-cant-handle-mix-of-binary-and-continuous-target\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#https://karateclub.readthedocs.io/en/latest/modules/root.html\n",
        "from karateclub import WaveletCharacteristic\n",
        "from karateclub import LDP\n",
        "from karateclub import FeatherGraph\n",
        "from karateclub import GeoScattering\n",
        "from karateclub import IGE\n",
        "from karateclub import GL2Vec\n",
        "from karateclub import NetLSD\n",
        "from karateclub import SF\n",
        "from karateclub import FGSD\n",
        "from karateclub import Graph2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cfcc655",
      "metadata": {
        "id": "6cfcc655"
      },
      "outputs": [],
      "source": [
        "f = open('reddit_edges.json')\n",
        "graph_hash = json.load(f)\n",
        "df = pd.read_csv('reddit_target.csv')\n",
        "\n",
        "#extract first 1000 X values\n",
        "graph_array = list(graph_hash.values())\n",
        "G = [nx.Graph(i) for i in graph_array[0:1000]]\n",
        "\n",
        "#extract first 1000 y values\n",
        "y = list(df.target)[0:1000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a7f7e0b",
      "metadata": {
        "id": "6a7f7e0b"
      },
      "outputs": [],
      "source": [
        "model = GL2Vec(wl_iterations=10)\n",
        "model.fit(G)\n",
        "GL_X = model.get_embedding()\n",
        "\n",
        "#WaveletCharacteristic(order: int = 5, eval_points: int = 25, theta_max: float = 2.5, tau: float = 1.0, pooling: str = 'mean')\n",
        "#LDP(bins: int = 32)\n",
        "#FeatherGraph(order: int = 5, eval_points: int = 25, theta_max: float = 2.5, seed: int = 42, pooling: str = 'mean')\n",
        "#IGE(feature_embedding_dimensions: List[int] = [3, 5], spectral_embedding_dimensions: List[int] = [10, 20], histogram_bins: List[int] = [10, 20], seed: int = 42)\n",
        "#GeoScattering(order: int = 4, moments: int = 4, seed: int = 42)\n",
        "#GL2Vec(wl_iterations: int = 2, dimensions: int = 128, workers: int = 4, down_sampling: float = 0.0001, epochs: int = 10, learning_rate: float = 0.025, min_count: int = 5, seed: int = 42, erase_base_features: bool = False)\n",
        "#NetLSD(scale_min: float = -2.0, scale_max: float = 2.0, scale_steps: int = 250, approximations: int = 200, seed: int = 42)\n",
        "#SF(dimensions: int = 128, seed: int = 42)\n",
        "#FGSD(hist_bins: int = 200, hist_range: int = 20, seed: int = 42)\n",
        "#Graph2Vec(wl_iterations: int = 2, attributed: bool = False, dimensions: int = 128, workers: int = 4, down_sampling: float = 0.0001, epochs: int = 10, learning_rate: float = 0.025, min_count: int = 5, seed: int = 42, erase_base_features: bool = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = WaveletCharacteristic()\n",
        "model.fit(G)\n",
        "W_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "UW3wT9LbdOx3"
      },
      "id": "UW3wT9LbdOx3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LDP()\n",
        "model.fit(G)\n",
        "LDP_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "bjlqt6NRdBy7"
      },
      "id": "bjlqt6NRdBy7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FeatherGraph()\n",
        "model.fit(G)\n",
        "F_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "MnJpLVGgdHH1"
      },
      "id": "MnJpLVGgdHH1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = IGE()\n",
        "model.fit(G)\n",
        "IGE_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "y86jTqZXdHSP"
      },
      "id": "y86jTqZXdHSP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GeoScattering()\n",
        "model.fit(G)\n",
        "G_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "p96sc25edHZ7"
      },
      "id": "p96sc25edHZ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetLSD()\n",
        "model.fit(G)\n",
        "NetLSD_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "vYVzK2bmdHhG"
      },
      "id": "vYVzK2bmdHhG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SF()\n",
        "model.fit(G)\n",
        "SF_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "ZR2UbaE1dIxU"
      },
      "id": "ZR2UbaE1dIxU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FGSD()\n",
        "model.fit(G)\n",
        "FGSD_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "Gj4q8VWRdI29"
      },
      "id": "Gj4q8VWRdI29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Graph2Vec(wl_iterations=10)\n",
        "model.fit(G)\n",
        "Graph_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "qPoWg5pEga6L"
      },
      "id": "qPoWg5pEga6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6d230b",
      "metadata": {
        "id": "eb6d230b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2a133e-a665-461a-a137-5ce79e13a275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GL2Vec\n",
            "GL_Accuracy: 137.000000\n",
            "GL_AUC: 0.708738\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(GL_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "GL_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "GL_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GL2Vec')\n",
        "print('GL_Accuracy: {:f}'.format(GL_acc))\n",
        "print('GL_AUC: {:f}'.format(GL_auc))\n",
        "#wl 100 AUC: 0.7445\n",
        "#https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter\n",
        "#increase to max_iter=200 from max_iter=100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Winner!\n",
        "X_train, X_test, y_train, y_test = train_test_split(W_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "W_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "W_auc = roc_auc_score(y_test, y_pred)\n",
        "print('WaveletCharacteristic')\n",
        "print('W_Accuracy: {:f}'.format(W_acc))\n",
        "print('W_AUC: {:f}'.format(W_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZgo7cF9d2Uy",
        "outputId": "7ba347c6-7af0-4c1d-d305-68ab7a5510aa"
      },
      "id": "PZgo7cF9d2Uy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WaveletCharacteristic\n",
            "W_Accuracy: 154.000000\n",
            "W_AUC: 0.830898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(LDP_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "LDP_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "LDP_auc = roc_auc_score(y_test, y_pred)\n",
        "print('LDP')\n",
        "print('LDP_Accuracy: {:f}'.format(LDP_acc))\n",
        "print('LDP_AUC: {:f}'.format(LDP_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8k71H_Ad2do",
        "outputId": "f627b6d3-6b0e-4112-c3ce-0993093fa4a6"
      },
      "id": "l8k71H_Ad2do",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDP\n",
            "LDP_Accuracy: 144.000000\n",
            "LDP_AUC: 0.795366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(F_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "F_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "F_auc = roc_auc_score(y_test, y_pred)\n",
        "print('FeatherGraph')\n",
        "print('F_Accuracy: {:f}'.format(F_acc))\n",
        "print('F_AUC: {:f}'.format(F_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20F-aaNbd2lB",
        "outputId": "37347e5a-676c-47f4-ba0b-97af886dbcdc"
      },
      "id": "20F-aaNbd2lB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeatherGraph\n",
            "F_Accuracy: 147.000000\n",
            "F_AUC: 0.809979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#even at max_iter=1000 it does not converge\n",
        "X_train, X_test, y_train, y_test = train_test_split(IGE_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "IGE_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "IGE_auc = roc_auc_score(y_test, y_pred)\n",
        "print('IGE')\n",
        "print('IGE_Accuracy: {:f}'.format(IGE_acc))\n",
        "print('IGE_AUC: {:f}'.format(IGE_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj6Pryild2p2",
        "outputId": "5fc74358-fddc-4fe0-80b7-ca433be94ef2"
      },
      "id": "Zj6Pryild2p2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IGE\n",
            "IGE_Accuracy: 143.000000\n",
            "IGE_AUC: 0.784506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(G_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "G_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "G_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GeoScattering')\n",
        "print('G_Accuracy: {:f}'.format(G_acc))\n",
        "print('G_AUC: {:f}'.format(G_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfdKY1i2d2uf",
        "outputId": "49fcf582-d25a-45dc-a9f8-e04e07c675c0"
      },
      "id": "JfdKY1i2d2uf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GeoScattering\n",
            "G_Accuracy: 155.000000\n",
            "G_AUC: 0.817386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(NetLSD_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "NetLSD_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "NetLSD_auc = roc_auc_score(y_test, y_pred)\n",
        "print('NetLSD')\n",
        "print('NetLSD_Accuracy: {:f}'.format(NetLSD_acc))\n",
        "print('NetLSD_AUC: {:f}'.format(NetLSD_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr4lp8zyd22W",
        "outputId": "0bfe1e54-27dd-458b-d509-12d3462232cf"
      },
      "id": "lr4lp8zyd22W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetLSD\n",
            "NetLSD_Accuracy: 151.000000\n",
            "NetLSD_AUC: 0.810580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(SF_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "SF_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "SF_auc = roc_auc_score(y_test, y_pred)\n",
        "print('SF')\n",
        "print('SF_Accuracy: {:f}'.format(SF_acc))\n",
        "print('SF_AUC: {:f}'.format(SF_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x8A2Zwed28z",
        "outputId": "3bf0b2ea-0717-4aac-86e5-fe03c35709de"
      },
      "id": "0x8A2Zwed28z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SF\n",
            "SF_Accuracy: 148.000000\n",
            "SF_AUC: 0.787208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#note even at max_iter=500 it does not converge\n",
        "X_train, X_test, y_train, y_test = train_test_split(FGSD_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "FGSD_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "FGSD_auc = roc_auc_score(y_test, y_pred)\n",
        "print('FGSD')\n",
        "print('FGSD_Accuracy: {:f}'.format(FGSD_acc))\n",
        "print('FGSD_AUC: {:f}'.format(FGSD_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktKaDyWwd3H2",
        "outputId": "c156a9f5-f134-4cd6-e73f-90ff03d835f2"
      },
      "id": "ktKaDyWwd3H2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSD\n",
            "FGSD_Accuracy: 146.000000\n",
            "FGSD_AUC: 0.787409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Graph_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "Graph_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "Graph_auc = roc_auc_score(y_test, y_pred)\n",
        "print('Graph2Vec')\n",
        "print('Graph_Accuracy: {:f}'.format(Graph_acc))\n",
        "print('Graph_AUC: {:f}'.format(Graph_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKSe6gtfgk90",
        "outputId": "9302a6cf-dba2-4e31-8542-79311e5dc2e8"
      },
      "id": "DKSe6gtfgk90",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph2Vec\n",
            "Graph_Accuracy: 124.000000\n",
            "Graph_AUC: 0.637774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Winner seems to be:\n",
        "**WaveletCharacteristic**\n",
        "W_Accuracy: 154.000000\n",
        "W_AUC: 0.830898"
      ],
      "metadata": {
        "id": "Y-IlxKMiifYP"
      },
      "id": "Y-IlxKMiifYP"
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing logistic to SVM. Using manual rounding to see better AUC score"
      ],
      "metadata": {
        "id": "M4q9q5yJil7T"
      },
      "id": "M4q9q5yJil7T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#refresh GL2Vec\n",
        "model = GL2Vec(wl_iterations=10)\n",
        "model.fit(G)\n",
        "GL_X = model.get_embedding()"
      ],
      "metadata": {
        "id": "eKGdN6AlimEB"
      },
      "id": "eKGdN6AlimEB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic\n",
        "X_train, X_test, y_train, y_test = train_test_split(GL_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict(X_test)\n",
        "GL_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "GL_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GL2Vec')\n",
        "print('GL_Accuracy: {:f}'.format(GL_acc))\n",
        "print('GL_AUC: {:f}'.format(GL_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEXbkOTLjsni",
        "outputId": "253457f0-6ade-4aac-d1a5-5af3ed227c0c"
      },
      "id": "SEXbkOTLjsni",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GL2Vec\n",
            "GL_Accuracy: 137.000000\n",
            "GL_AUC: 0.684866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic manual round\n",
        "X_train, X_test, y_train, y_test = train_test_split(GL_X, y, test_size=0.2, random_state=42)\n",
        "log_model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = log_model.predict_proba(X_test)[:, 1]\n",
        "GL_acc = accuracy_score(y_test, y_pred.round(), normalize=False)\n",
        "GL_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GL2Vec')\n",
        "print('GL_Accuracy: {:f}'.format(GL_acc))\n",
        "print('GL_AUC: {:f}'.format(GL_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75yLLLt_j1Gk",
        "outputId": "15cf5961-006a-4936-a169-298d7cf0412e"
      },
      "id": "75yLLLt_j1Gk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GL2Vec\n",
            "GL_Accuracy: 137.000000\n",
            "GL_AUC: 0.719848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "X_train, X_test, y_train, y_test = train_test_split(GL_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "GL_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "GL_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GL2Vec SVM')\n",
        "print('GL_Accuracy: {:f}'.format(GL_acc))\n",
        "print('GL_AUC: {:f}'.format(GL_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9hF8ddwizQu",
        "outputId": "c6aac3e4-edb1-4ac3-e749-435c8ba62a2f"
      },
      "id": "w9hF8ddwizQu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GL2Vec SVM\n",
            "GL_Accuracy: 137.000000\n",
            "GL_AUC: 0.684566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM ALL\n",
        "X_train, X_test, y_train, y_test = train_test_split(GL_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "GL_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "GL_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GL2Vec SVM')\n",
        "print('GL_Accuracy: {:f}'.format(GL_acc))\n",
        "print('GL_AUC: {:f}'.format(GL_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(W_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "W_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "W_auc = roc_auc_score(y_test, y_pred)\n",
        "print('WaveletCharacteristic SVM')\n",
        "print('W_Accuracy: {:f}'.format(W_acc))\n",
        "print('W_AUC: {:f}'.format(W_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(LDP_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "LDP_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "LDP_auc = roc_auc_score(y_test, y_pred)\n",
        "print('LDP SVM')\n",
        "print('LDP_Accuracy: {:f}'.format(LDP_acc))\n",
        "print('LDP_AUC: {:f}'.format(LDP_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(F_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "F_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "F_auc = roc_auc_score(y_test, y_pred)\n",
        "print('FeatherGraph SVM')\n",
        "print('F_Accuracy: {:f}'.format(F_acc))\n",
        "print('F_AUC: {:f}'.format(F_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(IGE_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "IGE_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "IGE_auc = roc_auc_score(y_test, y_pred)\n",
        "print('IGE SVM')\n",
        "print('IGE_Accuracy: {:f}'.format(IGE_acc))\n",
        "print('IGE_AUC: {:f}'.format(IGE_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(G_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "G_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "G_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GeoScattering SVM')\n",
        "print('G_Accuracy: {:f}'.format(G_acc))\n",
        "print('G_AUC: {:f}'.format(G_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(NetLSD_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "NetLSD_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "NetLSD_auc = roc_auc_score(y_test, y_pred)\n",
        "print('NetLSD SVM')\n",
        "print('NetLSD_Accuracy: {:f}'.format(NetLSD_acc))\n",
        "print('NetLSD_AUC: {:f}'.format(NetLSD_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(SF_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "SF_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "SF_auc = roc_auc_score(y_test, y_pred)\n",
        "print('SF SVM')\n",
        "print('SF_Accuracy: {:f}'.format(SF_acc))\n",
        "print('SF_AUC: {:f}'.format(SF_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(FGSD_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "FGSD_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "FGSD_auc = roc_auc_score(y_test, y_pred)\n",
        "print('FGSD SVM')\n",
        "print('FGSD_Accuracy: {:f}'.format(FGSD_acc))\n",
        "print('FGSD_AUC: {:f}'.format(FGSD_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Graph_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "Graph_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
        "Graph_auc = roc_auc_score(y_test, y_pred)\n",
        "print('Graph2Vec SVM')\n",
        "print('Graph_Accuracy: {:f}'.format(Graph_acc))\n",
        "print('Graph_AUC: {:f}'.format(Graph_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddcevn-BlCOE",
        "outputId": "5a08e6a5-32c6-4a81-a7fb-9fae874afb01"
      },
      "id": "ddcevn-BlCOE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GL2Vec SVM\n",
            "GL_Accuracy: 137.000000\n",
            "GL_AUC: 0.684566\n",
            "WaveletCharacteristic SVM\n",
            "W_Accuracy: 151.000000\n",
            "W_AUC: 0.754029\n",
            "LDP SVM\n",
            "LDP_Accuracy: 154.000000\n",
            "LDP_AUC: 0.767691\n",
            "FeatherGraph SVM\n",
            "F_Accuracy: 149.000000\n",
            "F_AUC: 0.743719\n",
            "IGE SVM\n",
            "IGE_Accuracy: 125.000000\n",
            "IGE_AUC: 0.619107\n",
            "GeoScattering SVM\n",
            "G_Accuracy: 129.000000\n",
            "G_AUC: 0.634621\n",
            "NetLSD SVM\n",
            "NetLSD_Accuracy: 142.000000\n",
            "NetLSD_AUC: 0.703433\n",
            "SF SVM\n",
            "SF_Accuracy: 146.000000\n",
            "SF_AUC: 0.728856\n",
            "FGSD SVM\n",
            "FGSD_Accuracy: 145.000000\n",
            "FGSD_AUC: 0.724002\n",
            "Graph2Vec SVM\n",
            "Graph_Accuracy: 126.000000\n",
            "Graph_AUC: 0.633570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM ALL Normalized\n",
        "X_train, X_test, y_train, y_test = train_test_split(GL_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "GL_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "GL_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GL2Vec SVM')\n",
        "print('GL_Accuracy: {:f}'.format(GL_acc))\n",
        "print('GL_AUC: {:f}'.format(GL_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(W_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "W_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "W_auc = roc_auc_score(y_test, y_pred)\n",
        "print('WaveletCharacteristic SVM')\n",
        "print('W_Accuracy: {:f}'.format(W_acc))\n",
        "print('W_AUC: {:f}'.format(W_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(LDP_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "LDP_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "LDP_auc = roc_auc_score(y_test, y_pred)\n",
        "print('LDP SVM')\n",
        "print('LDP_Accuracy: {:f}'.format(LDP_acc))\n",
        "print('LDP_AUC: {:f}'.format(LDP_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(F_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "F_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "F_auc = roc_auc_score(y_test, y_pred)\n",
        "print('FeatherGraph SVM')\n",
        "print('F_Accuracy: {:f}'.format(F_acc))\n",
        "print('F_AUC: {:f}'.format(F_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(IGE_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "IGE_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "IGE_auc = roc_auc_score(y_test, y_pred)\n",
        "print('IGE SVM')\n",
        "print('IGE_Accuracy: {:f}'.format(IGE_acc))\n",
        "print('IGE_AUC: {:f}'.format(IGE_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(G_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "G_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "G_auc = roc_auc_score(y_test, y_pred)\n",
        "print('GeoScattering SVM')\n",
        "print('G_Accuracy: {:f}'.format(G_acc))\n",
        "print('G_AUC: {:f}'.format(G_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(NetLSD_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "NetLSD_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "NetLSD_auc = roc_auc_score(y_test, y_pred)\n",
        "print('NetLSD SVM')\n",
        "print('NetLSD_Accuracy: {:f}'.format(NetLSD_acc))\n",
        "print('NetLSD_AUC: {:f}'.format(NetLSD_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(SF_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "SF_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "SF_auc = roc_auc_score(y_test, y_pred)\n",
        "print('SF SVM')\n",
        "print('SF_Accuracy: {:f}'.format(SF_acc))\n",
        "print('SF_AUC: {:f}'.format(SF_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(FGSD_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "FGSD_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "FGSD_auc = roc_auc_score(y_test, y_pred)\n",
        "print('FGSD SVM')\n",
        "print('FGSD_Accuracy: {:f}'.format(FGSD_acc))\n",
        "print('FGSD_AUC: {:f}'.format(FGSD_auc))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Graph_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "Graph_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "Graph_auc = roc_auc_score(y_test, y_pred)\n",
        "print('Graph2Vec SVM')\n",
        "print('Graph_Accuracy: {:f}'.format(Graph_acc))\n",
        "print('Graph_AUC: {:f}'.format(Graph_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8vFBmPGu-Zi",
        "outputId": "e77a1209-2adc-4693-956b-a7fb47a0969d"
      },
      "id": "r8vFBmPGu-Zi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GL2Vec SVM\n",
            "GL_Accuracy: 0.685000\n",
            "GL_AUC: 0.684566\n",
            "WaveletCharacteristic SVM\n",
            "W_Accuracy: 0.755000\n",
            "W_AUC: 0.754029\n",
            "LDP SVM\n",
            "LDP_Accuracy: 0.770000\n",
            "LDP_AUC: 0.767691\n",
            "FeatherGraph SVM\n",
            "F_Accuracy: 0.745000\n",
            "F_AUC: 0.743719\n",
            "IGE SVM\n",
            "IGE_Accuracy: 0.625000\n",
            "IGE_AUC: 0.619107\n",
            "GeoScattering SVM\n",
            "G_Accuracy: 0.645000\n",
            "G_AUC: 0.634621\n",
            "NetLSD SVM\n",
            "NetLSD_Accuracy: 0.710000\n",
            "NetLSD_AUC: 0.703433\n",
            "SF SVM\n",
            "SF_Accuracy: 0.730000\n",
            "SF_AUC: 0.728856\n",
            "FGSD SVM\n",
            "FGSD_Accuracy: 0.725000\n",
            "FGSD_AUC: 0.724002\n",
            "Graph2Vec SVM\n",
            "Graph_Accuracy: 0.630000\n",
            "Graph_AUC: 0.633570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Winner for SVM seems to be LDP but a close second is the winner from logistic regression (WaveletCharacteristic). Because Logistic regression was not converging for some techniques, going to go with SVM. The winner seems to be LDP only due to tuning reasons. LDP only has 1 factor. If I tune WaveletCharacteristic I can probably get a higher score. "
      ],
      "metadata": {
        "id": "t0kmfeynns2G"
      },
      "id": "t0kmfeynns2G"
    },
    {
      "cell_type": "code",
      "source": [
        "#WaveletCharacteristic(order: int = 5, eval_points: int = 25, theta_max: float = 2.5, tau: float = 1.0, pooling: str = 'mean')\n",
        "#LDP(bins: int = 32)\n",
        "#FeatherGraph(order: int = 5, eval_points: int = 25, theta_max: float = 2.5, seed: int = 42, pooling: str = 'mean')\n",
        "#IGE(feature_embedding_dimensions: List[int] = [3, 5], spectral_embedding_dimensions: List[int] = [10, 20], histogram_bins: List[int] = [10, 20], seed: int = 42)\n",
        "#GeoScattering(order: int = 4, moments: int = 4, seed: int = 42)\n",
        "#GL2Vec(wl_iterations: int = 2, dimensions: int = 128, workers: int = 4, down_sampling: float = 0.0001, epochs: int = 10, learning_rate: float = 0.025, min_count: int = 5, seed: int = 42, erase_base_features: bool = False)\n",
        "#NetLSD(scale_min: float = -2.0, scale_max: float = 2.0, scale_steps: int = 250, approximations: int = 200, seed: int = 42)\n",
        "#SF(dimensions: int = 128, seed: int = 42)\n",
        "#FGSD(hist_bins: int = 200, hist_range: int = 20, seed: int = 42)\n",
        "#Graph2Vec(wl_iterations: int = 2, attributed: bool = False, dimensions: int = 128, workers: int = 4, down_sampling: float = 0.0001, epochs: int = 10, learning_rate: float = 0.025, min_count: int = 5, seed: int = 42, erase_base_features: bool = False)"
      ],
      "metadata": {
        "id": "6JUZmG8VokkE"
      },
      "id": "6JUZmG8VokkE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have tuned Graph2Vec and GL2Vec with wl_iterations = 10. The other parameters seem reasonable. Yet Graph2Vec and GL2Vec dont perform well. LDP performed well but seems to be maxed out as there are few parameters to tune. SF, FGSD, and GeoScattering all seem to be maxed out as there are few parameters to tune.\n",
        "This leaves the final candidates as: WaveletCharacteristic, FeatherGraph, IGE and NetLSD. GE and NetLSD seem way off compared to WaveletCharacteristic and FeatherGraph, so will focus on tuning these two. Coincidentally, WaveletCharacteristic and FeatherGraph are the two newest algorithms. This makes sense as algorithms improve/become more expressive over time. Note that NN models doesnt perform well on tabular data unless there is a ton of rich meta data which we do not have. This is why we omitted a NN model."
      ],
      "metadata": {
        "id": "CimlM1aNozUf"
      },
      "id": "CimlM1aNozUf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Future, investigate LDP, WaveletCharacteristic and FeatherGraph"
      ],
      "metadata": {
        "id": "lnHSu8DPqi5O"
      },
      "id": "lnHSu8DPqi5O"
    },
    {
      "cell_type": "code",
      "source": [
        "LDP_X # LDP\n",
        "W_X # Wavelet\n",
        "F_X # Feather\n",
        "LDP_X_df = pd.DataFrame(LDP_X)\n",
        "W_X_df = pd.DataFrame(10*W_X) #need to normalize\n",
        "F_X_df = pd.DataFrame(10*F_X) #need to normalize\n",
        "ensemble_df = pd.concat([LDP_X_df, W_X_df, F_X_df], axis=1, join=\"inner\")\n",
        "#ensemble_df\n",
        "Ensemble_X = ensemble_df.to_numpy()\n",
        "#len(Ensemble_X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Ensemble_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "SF_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "SF_auc = roc_auc_score(y_test, y_pred)\n",
        "print('Ensemble SVM')\n",
        "print('Ensemble_Accuracy: {:f}'.format(SF_acc))\n",
        "print('Ensemble_AUC: {:f}'.format(SF_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djbEyZ8qKDNl",
        "outputId": "f1a727d7-1a48-4113-b4a8-9d1bfe91736a"
      },
      "id": "djbEyZ8qKDNl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble SVM\n",
            "Ensemble_Accuracy: 0.780000\n",
            "Ensemble_AUC: 0.776799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydsREACmA11O",
        "outputId": "750f2eb7-52e4-45d0-fc01-2b8781b8bd78"
      },
      "id": "ydsREACmA11O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1660)"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LDP_X # LDP\n",
        "W_X # Wavelet\n",
        "F_X # Feather\n",
        "LDP_X_df = pd.DataFrame(LDP_X)\n",
        "W_X_df = pd.DataFrame(10*W_X) #need to normalize\n",
        "F_X_df = pd.DataFrame(10*F_X) #need to normalize\n",
        "GL_X\n",
        "IGE_X\n",
        "G_X\n",
        "NetLSD_X\n",
        "SF_X\n",
        "FGSD_X\n",
        "Graph_X\n",
        "\n",
        "GL_X_df = pd.DataFrame(10*GL_X) #need to normalize\n",
        "IGE_X_df = pd.DataFrame(10*IGE_X) #need to normalize\n",
        "SF_X_df = pd.DataFrame(10*SF_X) #need to normalize\n",
        "FGSD_X_df = pd.DataFrame(FGSD_X/10) #need to normalize\n",
        "Graph_X_df = pd.DataFrame(10*Graph_X) #need to normalize\n",
        "\n",
        "ensemble_df = pd.concat([LDP_X_df, W_X_df, F_X_df, GL_X_df, IGE_X_df, SF_X_df, FGSD_X_df, Graph_X_df], axis=1, join=\"inner\")\n",
        "#ensemble_df\n",
        "Ensemble_X = ensemble_df.to_numpy()\n",
        "#len(Ensemble_X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Ensemble_X, y, test_size=0.2, random_state=42)\n",
        "SVM_model = svm.SVC().fit(X_train, y_train)\n",
        "y_pred = SVM_model.predict(X_test)\n",
        "SF_acc = accuracy_score(y_test, y_pred, normalize=True)\n",
        "SF_auc = roc_auc_score(y_test, y_pred)\n",
        "print('Full Ensemble SVM')\n",
        "print('Full Ensemble_Accuracy: {:f}'.format(SF_acc))\n",
        "print('Full Ensemble_AUC: {:f}'.format(SF_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJCWerEsVl-i",
        "outputId": "da6890fc-a978-4c18-8fb8-919d747ef80d"
      },
      "id": "PJCWerEsVl-i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Ensemble SVM\n",
            "Full Ensemble_Accuracy: 0.625000\n",
            "Full Ensemble_AUC: 0.619107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "ensemble_tensor = torch.from_numpy(X_train)\n",
        "ensemble_tensor.dtype\n",
        "ensemble_tensor = ensemble_tensor.clone().to(torch.float32)\n"
      ],
      "metadata": {
        "id": "Ddy86aAxZkJb"
      },
      "id": "Ddy86aAxZkJb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ensemble_tensor)\n",
        "Xbatch = ensemble_tensor[i:i+batch_size]\n",
        "Xbatch.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0usyzfRcSU-",
        "outputId": "53f301f9-209f-4b47-c5c5-573deee75781"
      },
      "id": "R0usyzfRcSU-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([0, 2976])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BiClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.hidden1 = nn.Linear(ensemble_tensor.shape[1], 256)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.hidden2 = nn.Linear(256, 256)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.output = nn.Linear(256, 1)\n",
        "        self.act_output = nn.Sigmoid()\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.act1(self.hidden1(x))\n",
        "        x = self.act2(self.hidden2(x))\n",
        "        x = self.act_output(self.output(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "model = BiClassifier()\n",
        " \n",
        "# train the model\n",
        "loss_fn   = nn.BCELoss()  # binary cross entropy\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "n_epochs = 200\n",
        "batch_size = 5\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-swNiJ_dQcw",
        "outputId": "09f8bb36-0643-45bb-dc09-87ce83158675"
      },
      "id": "V-swNiJ_dQcw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiClassifier(\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (hidden1): Linear(in_features=2976, out_features=256, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (hidden2): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (act2): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (act_output): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ensemble_tensor.shape)\n",
        "print(ensemble_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eByAGhOiddt",
        "outputId": "56dc186c-921c-4786-9fdd-7db40db11b50"
      },
      "id": "5eByAGhOiddt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([800, 2976])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xbatch.shape\n",
        "print(Xbatch.shape)\n",
        "print(Xbatch.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuWGof8jggmU",
        "outputId": "fd7465be-2073-4424-a9be-5f42f1039d2f"
      },
      "id": "OuWGof8jggmU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([0, 2976])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_t = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "y_t"
      ],
      "metadata": {
        "id": "KB9mxTdUjzEV"
      },
      "id": "KB9mxTdUjzEV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ybatch = y_t[i:i+batch_size]\n",
        "ybatch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMKmHYm5eIh_",
        "outputId": "aadd4880-c274-4737-fe72-911524ecfb23"
      },
      "id": "HMKmHYm5eIh_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([], size=(0, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zggd4t8MgSPm",
        "outputId": "e5cdb16b-10be-42cb-f9cb-4c723700096f"
      },
      "id": "Zggd4t8MgSPm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6swXIB3kkaWL",
        "outputId": "a5b5e546-b30a-4322-a672-9ad419f9a4bc"
      },
      "id": "6swXIB3kkaWL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([800, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0t7p5_Gkm3W",
        "outputId": "9e8de5fe-fb15-49a1-b487-1179560469d1"
      },
      "id": "G0t7p5_Gkm3W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "n_epochs = 200\n",
        "batch_size = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(0, len(ensemble_tensor), batch_size):\n",
        "        Xbatch = ensemble_tensor[i:i+batch_size]\n",
        "        y_pred = model(Xbatch)\n",
        "        ybatch = y_t[i:i+batch_size]\n",
        "        loss = loss_fn(y_pred, ybatch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        " \n",
        "# compute accuracy\n",
        "y_pred = model(ensemble_tensor)\n",
        "# accuracy = (y_pred.round() == y_test).float().mean()\n",
        "# print(f\"Accuracy {accuracy}\")\n",
        " \n",
        "# # make class predictions with the model\n",
        "# predictions = (model(X_test) > 0.5).int()\n",
        "# for i in range(5):\n",
        "#     print('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))"
      ],
      "metadata": {
        "id": "9ep0ZRjXX9yv"
      },
      "id": "9ep0ZRjXX9yv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = model(ensemble_tensor)\n",
        "# accuracy = (y_pred.round() == y_t).float().mean()\n",
        "# print(f\"Accuracy {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EYpUQsmn8V2",
        "outputId": "c8dc3144-88dc-44b0-dfc8-09f900329e26"
      },
      "id": "0EYpUQsmn8V2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8287500143051147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_numpy = y_pred.detach().numpy()\n",
        "y_round = y_numpy.round()"
      ],
      "metadata": {
        "id": "kAQK-FGapBSI"
      },
      "id": "kAQK-FGapBSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SF_acc = accuracy_score(y_t, y_round, normalize=True)\n",
        "SF_auc = roc_auc_score(y_t, y_round)"
      ],
      "metadata": {
        "id": "5Q9hrmDpom7b"
      },
      "id": "5Q9hrmDpom7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Full Ensemble NN')\n",
        "print('Full Ensemble_Accuracy: {:f}'.format(SF_acc))\n",
        "print('Full Ensemble_AUC: {:f}'.format(SF_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ccefCzpa3w",
        "outputId": "a98c7ce2-fbad-4201-c2be-271a27c75f31"
      },
      "id": "50ccefCzpa3w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Ensemble NN\n",
            "Full Ensemble_Accuracy: 0.857500\n",
            "Full Ensemble_AUC: 0.856986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch\n",
        "# !pip install torch_geometric\n",
        "# import torch\n",
        "# torchversion = torch.__version__\n",
        "\n",
        "# # Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# # Numpy for matrices\n",
        "# import numpy as np\n",
        "# np.random.seed(0)\n",
        "\n",
        "# # Visualization\n",
        "# import networkx as nx\n",
        "# from sklearn.manifold import TSNE\n",
        "# import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9Js8q_lPZUdb"
      },
      "id": "9Js8q_lPZUdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "# from torch.nn import Linear, Dropout\n",
        "# from torch_geometric.nn import GCNConv, GATv2Conv\n",
        "\n",
        "\n",
        "# class GCN(torch.nn.Module):\n",
        "#   \"\"\"Graph Convolutional Network\"\"\"\n",
        "#   def __init__(self, dim_in, dim_h, dim_out):\n",
        "#     super().__init__()\n",
        "#     self.gcn1 = GCNConv(dim_in, dim_h)\n",
        "#     self.gcn2 = GCNConv(dim_h, dim_out)\n",
        "#     self.optimizer = torch.optim.Adam(self.parameters(),\n",
        "#                                       lr=0.01,\n",
        "#                                       weight_decay=5e-4)\n",
        "\n",
        "#   def forward(self, x, edge_index):\n",
        "#     h = F.dropout(x, p=0.5, training=self.training)\n",
        "#     h = self.gcn1(h, edge_index)\n",
        "#     h = torch.relu(h)\n",
        "#     h = F.dropout(h, p=0.5, training=self.training)\n",
        "#     h = self.gcn2(h, edge_index)\n",
        "#     return h, F.log_softmax(h, dim=1)\n",
        "\n",
        "\n",
        "# class GAT(torch.nn.Module):\n",
        "#   \"\"\"Graph Attention Network\"\"\"\n",
        "#   def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
        "#     super().__init__()\n",
        "#     self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
        "#     self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n",
        "#     self.optimizer = torch.optim.Adam(self.parameters(),\n",
        "#                                       lr=0.005,\n",
        "#                                       weight_decay=5e-4)\n",
        "\n",
        "#   def forward(self, x, edge_index):\n",
        "#     h = F.dropout(x, p=0.6, training=self.training)\n",
        "#     h = self.gat1(x, edge_index)\n",
        "#     h = F.elu(h)\n",
        "#     h = F.dropout(h, p=0.6, training=self.training)\n",
        "#     h = self.gat2(h, edge_index)\n",
        "#     return h, F.log_softmax(h, dim=1)\n",
        "\n",
        "# def accuracy(pred_y, y):\n",
        "#     \"\"\"Calculate accuracy.\"\"\"\n",
        "#     return ((pred_y == y).sum() / len(y)).item()\n",
        "\n",
        "# def train(model, data):\n",
        "#     \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
        "#     criterion = torch.nn.CrossEntropyLoss()\n",
        "#     optimizer = model.optimizer\n",
        "#     epochs = 200\n",
        "\n",
        "#     model.train()\n",
        "#     for epoch in range(epochs+1):\n",
        "#         # Training\n",
        "#         optimizer.zero_grad()\n",
        "#         _, out = model(data.x, data.edge_index)\n",
        "#         loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "#         acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Validation\n",
        "#         val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "#         val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
        "\n",
        "#         # Print metrics every 10 epochs\n",
        "#         if(epoch % 10 == 0):\n",
        "#             print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
        "#                   f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
        "#                   f'Val Acc: {val_acc*100:.2f}%')\n",
        "          \n",
        "#     return model\n",
        "\n",
        "# def test(model, data):\n",
        "#     \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
        "#     model.eval()\n",
        "#     _, out = model(data.x, data.edge_index)\n",
        "#     acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
        "    return acc"
      ],
      "metadata": {
        "id": "WW_KcQ-yZeOH"
      },
      "id": "WW_KcQ-yZeOH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "\n",
        "# # Create GAT model\n",
        "# gat = GAT(dataset.num_features, 8, dataset.num_classes)\n",
        "# print(gat)\n",
        "\n",
        "# # Train\n",
        "# train(gat, data)\n",
        "\n",
        "# # Test\n",
        "# acc = test(gat, data)\n",
        "# print(f'\\nGAT test accuracy: {acc*100:.2f}%\\n')"
      ],
      "metadata": {
        "id": "P9VCF2ELZjye"
      },
      "id": "P9VCF2ELZjye",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gen_env",
      "language": "python",
      "name": "gen_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}